{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 読解用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e0e4bdf6-bcd9-4f82-a53b-9c5f685500a8",
    "_uuid": "66c995cf-7cbb-421b-bdd3-24906f5fb886",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tez\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from joblib import Parallel, delayed\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_map = {\n",
    "    \"B-Lead\": 0,\n",
    "    \"I-Lead\": 1,\n",
    "    \"B-Position\": 2,\n",
    "    \"I-Position\": 3,\n",
    "    \"B-Evidence\": 4,\n",
    "    \"I-Evidence\": 5,\n",
    "    \"B-Claim\": 6,\n",
    "    \"I-Claim\": 7,\n",
    "    \"B-Concluding Statement\": 8,\n",
    "    \"I-Concluding Statement\": 9,\n",
    "    \"B-Counterclaim\": 10,\n",
    "    \"I-Counterclaim\": 11,\n",
    "    \"B-Rebuttal\": 12,\n",
    "    \"I-Rebuttal\": 13,\n",
    "    \"O\": 14,\n",
    "    \"PAD\": -100,\n",
    "}\n",
    "\n",
    "\n",
    "id_target_map = {v: k for k, v in target_id_map.items()}\n",
    "\n",
    "class args1:\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n",
    "    tez_model= \"../input/fblongformerlarge1536/\"\n",
    "    output = \".\"\n",
    "    batch_size = 8\n",
    "    max_len = 4096\n",
    "    \n",
    "class args2:\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/longformerlarge4096/longformer-large-4096/\"\n",
    "    tez_model= \"../input/tez-fb-large/\"\n",
    "    output = \".\"\n",
    "    batch_size = 8\n",
    "    max_len = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackDataset:\n",
    "    def __init__(self, samples, max_len, tokenizer):\n",
    "        self.samples = samples\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.length = len(samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.samples[idx][\"input_ids\"]\n",
    "        # print(input_ids)\n",
    "        # print(input_labels)\n",
    "\n",
    "        # add start token id to the input_ids\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids\n",
    "\n",
    "        if len(input_ids) > self.max_len - 1:\n",
    "            input_ids = input_ids[: self.max_len - 1]\n",
    "\n",
    "        # add end token id to the input_ids\n",
    "        input_ids = input_ids + [self.tokenizer.sep_token_id]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # padding_length = self.max_len - len(input_ids)\n",
    "        # if padding_length > 0:\n",
    "        #     if self.tokenizer.padding_side == \"right\":\n",
    "        #         input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n",
    "        #         attention_mask = attention_mask + [0] * padding_length\n",
    "        #     else:\n",
    "        #         input_ids = [self.tokenizer.pad_token_id] * padding_length + input_ids\n",
    "        #         attention_mask = [0] * padding_length + attention_mask\n",
    "\n",
    "        # return {\n",
    "        #     \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        #     \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "        # }\n",
    "\n",
    "        return {\n",
    "            \"ids\": input_ids,\n",
    "            \"mask\": attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
    "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
    "\n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"ids\"]])\n",
    "\n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n",
    "        else:\n",
    "            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n",
    "\n",
    "        # convert to tensors\n",
    "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
    "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackModel(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        print(ids,mask)\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        print(logits)\n",
    "        return logits, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_test_data_helper(args, tokenizer, ids):\n",
    "    test_samples = []\n",
    "    for idx in ids:\n",
    "        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n",
    "        with open(filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "            \n",
    "        #print(text)\n",
    "        text = \"I like cat.\"\n",
    "        if idx == '18409261F5C2':\n",
    "            text = \"I do not like cat.\"\n",
    "        elif idx == 'D46BCB48440A':\n",
    "            text = \"I cat.\"\n",
    "        print(text.split())\n",
    "\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "\n",
    "        sample = {\n",
    "            \"id\": idx,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"text\": text,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "        }\n",
    "        print(sample)\n",
    "\n",
    "        test_samples.append(sample)\n",
    "    return test_samples\n",
    "\n",
    "\n",
    "def prepare_test_data(df, tokenizer, args):\n",
    "    test_samples = []\n",
    "    ids = df[\"id\"].unique()\n",
    "    ids_splits = np.array_split(ids, 4)\n",
    "\n",
    "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
    "        delayed(_prepare_test_data_helper)(args, tokenizer, idx) for idx in ids_splits\n",
    "    )\n",
    "    for result in results:\n",
    "        test_samples.extend(result)\n",
    "\n",
    "    return test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', 'not', 'like', 'cat.']\n",
      "\n",
      "{'id': '18409261F5C2', 'input_ids': [100, 109, 45, 101, 4758, 4], 'text': 'I do not like cat.', 'offset_mapping': [(0, 1), (2, 4), (5, 8), (9, 13), (14, 17), (17, 18)]}['I', 'cat.']\n",
      "{'id': 'D46BCB48440A', 'input_ids': [100, 4758, 4], 'text': 'I cat.', 'offset_mapping': [(0, 1), (2, 5), (5, 6)]}\n",
      "['I', 'like', 'cat.']\n",
      "{'id': '0FB0700DAF44', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)]}\n",
      "['I', 'like', 'cat.']\n",
      "{'id': 'D72CB1C11673', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)]}\n",
      "['I', 'like', 'cat.']\n",
      "{'id': 'DF920E0A7337', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)]}\n",
      "preds_iter\n",
      "<generator object Model.predict at 0x7f68b7dbf050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it, stage=test]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,  100,  109,   45,  101, 4758,    4,    2],\n",
      "        [   0,  100, 4758,    4,    2,    1,    1,    1],\n",
      "        [   0,  100,  101, 4758,    4,    2,    1,    1],\n",
      "        [   0,  100,  101, 4758,    4,    2,    1,    1],\n",
      "        [   0,  100,  101, 4758,    4,    2,    1,    1]], device='cuda:0') tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0]], device='cuda:0')\n",
      "tensor([[[4.9543e-05, 1.1803e-03, 2.3866e-04, 7.3373e-04, 2.1896e-04,\n",
      "          2.3944e-02, 1.1915e-04, 4.3006e-04, 4.9806e-04, 2.1946e-02,\n",
      "          3.1765e-05, 3.4870e-05, 1.1713e-05, 1.2029e-04, 9.5044e-01],\n",
      "         [1.4687e-03, 1.1124e-02, 1.0117e-02, 8.4042e-03, 5.4684e-03,\n",
      "          1.0000e-01, 2.5384e-03, 1.3776e-03, 2.8524e-02, 2.6138e-01,\n",
      "          3.8677e-04, 1.5462e-04, 1.7781e-04, 5.1932e-04, 5.6836e-01],\n",
      "         [2.4595e-05, 9.3580e-03, 2.7889e-04, 2.0325e-02, 1.7289e-04,\n",
      "          1.2116e-01, 1.2414e-04, 5.4134e-03, 3.2122e-04, 5.4240e-01,\n",
      "          3.0679e-05, 2.8914e-04, 1.7891e-05, 5.7602e-04, 2.9951e-01],\n",
      "         [2.2695e-05, 9.8105e-03, 2.2136e-04, 2.1551e-02, 1.3556e-04,\n",
      "          1.2390e-01, 9.7034e-05, 5.8966e-03, 2.7278e-04, 5.5392e-01,\n",
      "          2.8720e-05, 3.0616e-04, 1.6311e-05, 6.3641e-04, 2.8319e-01],\n",
      "         [2.3960e-05, 1.0012e-02, 2.1567e-04, 2.0376e-02, 1.4418e-04,\n",
      "          1.2358e-01, 9.4239e-05, 6.2621e-03, 2.5549e-04, 5.3966e-01,\n",
      "          2.7265e-05, 2.9574e-04, 1.4896e-05, 5.9081e-04, 2.9845e-01],\n",
      "         [2.5276e-05, 1.0180e-02, 1.8115e-04, 1.4239e-02, 1.3385e-04,\n",
      "          1.0993e-01, 9.3923e-05, 5.0630e-03, 2.4226e-04, 4.1714e-01,\n",
      "          2.5850e-05, 2.5271e-04, 1.2673e-05, 4.7875e-04, 4.4200e-01],\n",
      "         [1.9238e-05, 6.5439e-03, 1.2448e-04, 9.7407e-03, 1.2273e-04,\n",
      "          8.7571e-02, 7.1211e-05, 3.8418e-03, 1.9892e-04, 2.4721e-01,\n",
      "          2.0547e-05, 1.9125e-04, 1.2035e-05, 3.7143e-04, 6.4396e-01],\n",
      "         [2.4131e-05, 5.0397e-04, 9.8923e-05, 3.6634e-04, 1.0212e-04,\n",
      "          8.4735e-03, 5.6768e-05, 1.7642e-04, 2.2552e-04, 7.2406e-03,\n",
      "          1.4903e-05, 1.6779e-05, 5.5334e-06, 5.5468e-05, 9.8264e-01]],\n",
      "\n",
      "        [[1.1099e-04, 9.2458e-04, 1.8650e-04, 5.2188e-04, 2.8385e-04,\n",
      "          4.4447e-02, 1.0753e-04, 3.1813e-04, 1.0591e-04, 1.0887e-03,\n",
      "          5.0527e-05, 4.8066e-05, 1.4661e-05, 1.0439e-04, 9.5169e-01],\n",
      "         [1.0075e-03, 1.8565e-03, 8.5134e-04, 6.7421e-04, 1.1220e-03,\n",
      "          7.3791e-02, 3.9695e-04, 2.1870e-04, 5.4428e-04, 1.6248e-03,\n",
      "          1.6064e-04, 5.9455e-05, 5.0187e-05, 1.6657e-04, 9.1748e-01],\n",
      "         [3.2989e-05, 1.7321e-03, 7.3337e-05, 9.7336e-04, 8.6027e-05,\n",
      "          5.9228e-02, 4.7090e-05, 4.1806e-04, 3.5659e-05, 1.9169e-03,\n",
      "          3.0813e-05, 7.7723e-05, 7.5799e-06, 1.2684e-04, 9.3521e-01],\n",
      "         [4.9031e-05, 1.0188e-03, 8.6817e-05, 6.0885e-04, 1.3639e-04,\n",
      "          4.4416e-02, 5.3654e-05, 3.0072e-04, 4.9866e-05, 1.0443e-03,\n",
      "          2.9715e-05, 4.8706e-05, 9.1989e-06, 9.0636e-05, 9.5206e-01],\n",
      "         [5.6644e-05, 6.3435e-04, 9.1722e-05, 3.6235e-04, 1.5811e-04,\n",
      "          2.6940e-02, 6.4247e-05, 1.7243e-04, 5.3941e-05, 5.7983e-04,\n",
      "          3.2063e-05, 3.2325e-05, 8.5307e-06, 6.6242e-05, 9.7075e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01]],\n",
      "\n",
      "        [[4.0385e-05, 6.2845e-04, 1.5806e-04, 6.2844e-04, 2.3486e-04,\n",
      "          3.9810e-02, 1.1773e-04, 5.2719e-04, 1.8881e-04, 5.1559e-03,\n",
      "          2.8504e-05, 4.0604e-05, 8.1248e-06, 6.8217e-05, 9.5236e-01],\n",
      "         [1.1102e-03, 4.6200e-03, 5.3277e-03, 2.4655e-03, 4.9662e-03,\n",
      "          1.5798e-01, 2.3498e-03, 1.0830e-03, 7.9609e-03, 2.7898e-02,\n",
      "          2.4483e-04, 1.3427e-04, 1.0093e-04, 2.5705e-04, 7.8350e-01],\n",
      "         [1.8670e-05, 5.1743e-03, 1.9757e-04, 8.0508e-03, 1.7432e-04,\n",
      "          2.3287e-01, 1.2656e-04, 7.6508e-03, 1.2558e-04, 9.1351e-02,\n",
      "          2.6955e-05, 3.1924e-04, 1.1218e-05, 2.9233e-04, 6.5361e-01],\n",
      "         [1.6940e-05, 4.3875e-03, 1.2815e-04, 6.0645e-03, 1.2374e-04,\n",
      "          1.7982e-01, 9.4960e-05, 5.6079e-03, 9.1823e-05, 5.8305e-02,\n",
      "          1.9858e-05, 2.5501e-04, 7.6777e-06, 2.3958e-04, 7.4483e-01],\n",
      "         [9.1467e-06, 1.6723e-03, 5.8558e-05, 2.4971e-03, 8.1974e-05,\n",
      "          9.4541e-02, 4.8142e-05, 2.6016e-03, 4.8855e-05, 1.9155e-02,\n",
      "          1.2328e-05, 1.4406e-04, 5.0512e-06, 1.2492e-04, 8.7900e-01],\n",
      "         [1.2339e-05, 3.3743e-04, 5.6723e-05, 3.7138e-04, 9.7300e-05,\n",
      "          2.0297e-02, 5.0570e-05, 3.0318e-04, 6.1743e-05, 2.4220e-03,\n",
      "          1.3002e-05, 2.7919e-05, 3.6819e-06, 3.9915e-05, 9.7591e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01]],\n",
      "\n",
      "        [[4.0385e-05, 6.2845e-04, 1.5806e-04, 6.2844e-04, 2.3486e-04,\n",
      "          3.9810e-02, 1.1773e-04, 5.2719e-04, 1.8881e-04, 5.1559e-03,\n",
      "          2.8504e-05, 4.0604e-05, 8.1248e-06, 6.8217e-05, 9.5236e-01],\n",
      "         [1.1102e-03, 4.6200e-03, 5.3277e-03, 2.4655e-03, 4.9662e-03,\n",
      "          1.5798e-01, 2.3498e-03, 1.0830e-03, 7.9609e-03, 2.7898e-02,\n",
      "          2.4483e-04, 1.3427e-04, 1.0093e-04, 2.5705e-04, 7.8350e-01],\n",
      "         [1.8670e-05, 5.1743e-03, 1.9757e-04, 8.0508e-03, 1.7432e-04,\n",
      "          2.3287e-01, 1.2656e-04, 7.6508e-03, 1.2558e-04, 9.1351e-02,\n",
      "          2.6955e-05, 3.1924e-04, 1.1218e-05, 2.9233e-04, 6.5361e-01],\n",
      "         [1.6940e-05, 4.3875e-03, 1.2815e-04, 6.0645e-03, 1.2374e-04,\n",
      "          1.7982e-01, 9.4960e-05, 5.6079e-03, 9.1823e-05, 5.8305e-02,\n",
      "          1.9858e-05, 2.5501e-04, 7.6777e-06, 2.3958e-04, 7.4483e-01],\n",
      "         [9.1467e-06, 1.6723e-03, 5.8558e-05, 2.4971e-03, 8.1974e-05,\n",
      "          9.4541e-02, 4.8142e-05, 2.6016e-03, 4.8855e-05, 1.9155e-02,\n",
      "          1.2328e-05, 1.4406e-04, 5.0512e-06, 1.2492e-04, 8.7900e-01],\n",
      "         [1.2339e-05, 3.3743e-04, 5.6723e-05, 3.7138e-04, 9.7300e-05,\n",
      "          2.0297e-02, 5.0570e-05, 3.0318e-04, 6.1743e-05, 2.4220e-03,\n",
      "          1.3002e-05, 2.7919e-05, 3.6819e-06, 3.9915e-05, 9.7591e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01]],\n",
      "\n",
      "        [[4.0385e-05, 6.2845e-04, 1.5806e-04, 6.2844e-04, 2.3486e-04,\n",
      "          3.9810e-02, 1.1773e-04, 5.2719e-04, 1.8881e-04, 5.1559e-03,\n",
      "          2.8504e-05, 4.0604e-05, 8.1248e-06, 6.8217e-05, 9.5236e-01],\n",
      "         [1.1102e-03, 4.6200e-03, 5.3277e-03, 2.4655e-03, 4.9662e-03,\n",
      "          1.5798e-01, 2.3498e-03, 1.0830e-03, 7.9609e-03, 2.7898e-02,\n",
      "          2.4483e-04, 1.3427e-04, 1.0093e-04, 2.5705e-04, 7.8350e-01],\n",
      "         [1.8670e-05, 5.1743e-03, 1.9757e-04, 8.0508e-03, 1.7432e-04,\n",
      "          2.3287e-01, 1.2656e-04, 7.6508e-03, 1.2558e-04, 9.1351e-02,\n",
      "          2.6955e-05, 3.1924e-04, 1.1218e-05, 2.9233e-04, 6.5361e-01],\n",
      "         [1.6940e-05, 4.3875e-03, 1.2815e-04, 6.0645e-03, 1.2374e-04,\n",
      "          1.7982e-01, 9.4960e-05, 5.6079e-03, 9.1823e-05, 5.8305e-02,\n",
      "          1.9858e-05, 2.5501e-04, 7.6777e-06, 2.3958e-04, 7.4483e-01],\n",
      "         [9.1467e-06, 1.6723e-03, 5.8558e-05, 2.4971e-03, 8.1974e-05,\n",
      "          9.4541e-02, 4.8142e-05, 2.6016e-03, 4.8855e-05, 1.9155e-02,\n",
      "          1.2328e-05, 1.4406e-04, 5.0512e-06, 1.2492e-04, 8.7900e-01],\n",
      "         [1.2339e-05, 3.3743e-04, 5.6723e-05, 3.7138e-04, 9.7300e-05,\n",
      "          2.0297e-02, 5.0570e-05, 3.0318e-04, 6.1743e-05, 2.4220e-03,\n",
      "          1.3002e-05, 2.7919e-05, 3.6819e-06, 3.9915e-05, 9.7591e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01],\n",
      "         [3.9443e-02, 1.1846e-01, 2.8485e-02, 6.6377e-02, 7.4300e-02,\n",
      "          1.7068e-01, 2.7143e-02, 8.9538e-02, 2.4568e-02, 7.9811e-02,\n",
      "          1.7807e-02, 3.7511e-02, 3.9539e-02, 7.3073e-02, 1.1326e-01]]],\n",
      "       device='cuda:0')\n",
      "preds [[[4.9531e-05 1.1806e-03 2.3866e-04 7.3385e-04 2.1899e-04 2.3941e-02\n",
      "   1.1915e-04 4.3011e-04 4.9829e-04 2.1942e-02 3.1769e-05 3.4869e-05\n",
      "   1.1742e-05 1.2028e-04 9.5068e-01]\n",
      "  [1.4687e-03 1.1124e-02 1.0117e-02 8.4076e-03 5.4703e-03 9.9976e-02\n",
      "   2.5387e-03 1.3771e-03 2.8519e-02 2.6147e-01 3.8671e-04 1.5461e-04\n",
      "   1.7786e-04 5.1928e-04 5.6836e-01]\n",
      "  [2.4617e-05 9.3613e-03 2.7895e-04 2.0325e-02 1.7285e-04 1.2115e-01\n",
      "   1.2410e-04 5.4131e-03 3.2115e-04 5.4248e-01 3.0696e-05 2.8920e-04\n",
      "   1.7881e-05 5.7602e-04 2.9956e-01]\n",
      "  [2.2709e-05 9.8114e-03 2.2137e-04 2.1545e-02 1.3554e-04 1.2390e-01\n",
      "   9.7036e-05 5.8975e-03 2.7275e-04 5.5371e-01 2.8729e-05 3.0613e-04\n",
      "   1.6332e-05 6.3658e-04 2.8320e-01]\n",
      "  [2.3961e-05 1.0010e-02 2.1565e-04 2.0370e-02 1.4412e-04 1.2360e-01\n",
      "   9.4235e-05 6.2637e-03 2.5558e-04 5.3955e-01 2.7239e-05 2.9564e-04\n",
      "   1.4901e-05 5.9080e-04 2.9834e-01]\n",
      "  [2.5272e-05 1.0178e-02 1.8120e-04 1.4236e-02 1.3387e-04 1.0992e-01\n",
      "   9.3937e-05 5.0621e-03 2.4223e-04 4.1724e-01 2.5868e-05 2.5272e-04\n",
      "   1.2696e-05 4.7874e-04 4.4189e-01]\n",
      "  [1.9252e-05 6.5422e-03 1.2445e-04 9.7427e-03 1.2279e-04 8.7585e-02\n",
      "   7.1228e-05 3.8414e-03 1.9896e-04 2.4719e-01 2.0564e-05 1.9121e-04\n",
      "   1.2040e-05 3.7146e-04 6.4404e-01]\n",
      "  [2.4140e-05 5.0402e-04 9.8944e-05 3.6645e-04 1.0210e-04 8.4763e-03\n",
      "   5.6744e-05 1.7643e-04 2.2554e-04 7.2403e-03 1.4901e-05 1.6749e-05\n",
      "   5.5432e-06 5.5492e-05 9.8242e-01]]\n",
      "\n",
      " [[1.1098e-04 9.2459e-04 1.8656e-04 5.2166e-04 2.8396e-04 4.4434e-02\n",
      "   1.0753e-04 3.1805e-04 1.0592e-04 1.0891e-03 5.0545e-05 4.8041e-05\n",
      "   1.4663e-05 1.0437e-04 9.5166e-01]\n",
      "  [1.0071e-03 1.8568e-03 8.5115e-04 6.7425e-04 1.1215e-03 7.3792e-02\n",
      "   3.9697e-04 2.1875e-04 5.4407e-04 1.6251e-03 1.6069e-04 5.9426e-05\n",
      "   5.0187e-05 1.6654e-04 9.1748e-01]\n",
      "  [3.2961e-05 1.7319e-03 7.3314e-05 9.7322e-04 8.6010e-05 5.9235e-02\n",
      "   4.7088e-05 4.1795e-04 3.5644e-05 1.9169e-03 3.0816e-05 7.7724e-05\n",
      "   7.5698e-06 1.2684e-04 9.3506e-01]\n",
      "  [4.9055e-05 1.0185e-03 8.6844e-05 6.0892e-04 1.3638e-04 4.4403e-02\n",
      "   5.3644e-05 3.0065e-04 4.9889e-05 1.0443e-03 2.9743e-05 4.8697e-05\n",
      "   9.1791e-06 9.0659e-05 9.5215e-01]\n",
      "  [5.6624e-05 6.3419e-04 9.1732e-05 3.6240e-04 1.5807e-04 2.6947e-02\n",
      "   6.4254e-05 1.7238e-04 5.3942e-05 5.7983e-04 3.2067e-05 3.2306e-05\n",
      "   8.5235e-06 6.6221e-05 9.7070e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]]\n",
      "\n",
      " [[4.0412e-05 6.2847e-04 1.5807e-04 6.2847e-04 2.3484e-04 3.9795e-02\n",
      "   1.1772e-04 5.2738e-04 1.8883e-04 5.1575e-03 2.8491e-05 4.0591e-05\n",
      "   8.1062e-06 6.8188e-05 9.5215e-01]\n",
      "  [1.1101e-03 4.6196e-03 5.3291e-03 2.4662e-03 4.9667e-03 1.5796e-01\n",
      "   2.3499e-03 1.0834e-03 7.9575e-03 2.7893e-02 2.4486e-04 1.3423e-04\n",
      "   1.0091e-04 2.5702e-04 7.8369e-01]\n",
      "  [1.8656e-05 5.1727e-03 1.9753e-04 8.0490e-03 1.7428e-04 2.3291e-01\n",
      "   1.2660e-04 7.6523e-03 1.2553e-04 9.1370e-02 2.6941e-05 3.1924e-04\n",
      "   1.1206e-05 2.9230e-04 6.5381e-01]\n",
      "  [1.6928e-05 4.3869e-03 1.2815e-04 6.0654e-03 1.2374e-04 1.7981e-01\n",
      "   9.4950e-05 5.6076e-03 9.1851e-05 5.8319e-02 1.9848e-05 2.5511e-04\n",
      "   7.6890e-06 2.3961e-04 7.4463e-01]\n",
      "  [9.1195e-06 1.6727e-03 5.8532e-05 2.4967e-03 8.1956e-05 9.4543e-02\n",
      "   4.8161e-05 2.6016e-03 4.8876e-05 1.9150e-02 1.2338e-05 1.4400e-04\n",
      "   5.0664e-06 1.2493e-04 8.7891e-01]\n",
      "  [1.2338e-05 3.3736e-04 5.6744e-05 3.7146e-04 9.7275e-05 2.0294e-02\n",
      "   5.0545e-05 3.0327e-04 6.1750e-05 2.4223e-03 1.2994e-05 2.7895e-05\n",
      "   3.6955e-06 3.9935e-05 9.7607e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]]\n",
      "\n",
      " [[4.0412e-05 6.2847e-04 1.5807e-04 6.2847e-04 2.3484e-04 3.9795e-02\n",
      "   1.1772e-04 5.2738e-04 1.8883e-04 5.1575e-03 2.8491e-05 4.0591e-05\n",
      "   8.1062e-06 6.8188e-05 9.5215e-01]\n",
      "  [1.1101e-03 4.6196e-03 5.3291e-03 2.4662e-03 4.9667e-03 1.5796e-01\n",
      "   2.3499e-03 1.0834e-03 7.9575e-03 2.7893e-02 2.4486e-04 1.3423e-04\n",
      "   1.0091e-04 2.5702e-04 7.8369e-01]\n",
      "  [1.8656e-05 5.1727e-03 1.9753e-04 8.0490e-03 1.7428e-04 2.3291e-01\n",
      "   1.2660e-04 7.6523e-03 1.2553e-04 9.1370e-02 2.6941e-05 3.1924e-04\n",
      "   1.1206e-05 2.9230e-04 6.5381e-01]\n",
      "  [1.6928e-05 4.3869e-03 1.2815e-04 6.0654e-03 1.2374e-04 1.7981e-01\n",
      "   9.4950e-05 5.6076e-03 9.1851e-05 5.8319e-02 1.9848e-05 2.5511e-04\n",
      "   7.6890e-06 2.3961e-04 7.4463e-01]\n",
      "  [9.1195e-06 1.6727e-03 5.8532e-05 2.4967e-03 8.1956e-05 9.4543e-02\n",
      "   4.8161e-05 2.6016e-03 4.8876e-05 1.9150e-02 1.2338e-05 1.4400e-04\n",
      "   5.0664e-06 1.2493e-04 8.7891e-01]\n",
      "  [1.2338e-05 3.3736e-04 5.6744e-05 3.7146e-04 9.7275e-05 2.0294e-02\n",
      "   5.0545e-05 3.0327e-04 6.1750e-05 2.4223e-03 1.2994e-05 2.7895e-05\n",
      "   3.6955e-06 3.9935e-05 9.7607e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]]\n",
      "\n",
      " [[4.0412e-05 6.2847e-04 1.5807e-04 6.2847e-04 2.3484e-04 3.9795e-02\n",
      "   1.1772e-04 5.2738e-04 1.8883e-04 5.1575e-03 2.8491e-05 4.0591e-05\n",
      "   8.1062e-06 6.8188e-05 9.5215e-01]\n",
      "  [1.1101e-03 4.6196e-03 5.3291e-03 2.4662e-03 4.9667e-03 1.5796e-01\n",
      "   2.3499e-03 1.0834e-03 7.9575e-03 2.7893e-02 2.4486e-04 1.3423e-04\n",
      "   1.0091e-04 2.5702e-04 7.8369e-01]\n",
      "  [1.8656e-05 5.1727e-03 1.9753e-04 8.0490e-03 1.7428e-04 2.3291e-01\n",
      "   1.2660e-04 7.6523e-03 1.2553e-04 9.1370e-02 2.6941e-05 3.1924e-04\n",
      "   1.1206e-05 2.9230e-04 6.5381e-01]\n",
      "  [1.6928e-05 4.3869e-03 1.2815e-04 6.0654e-03 1.2374e-04 1.7981e-01\n",
      "   9.4950e-05 5.6076e-03 9.1851e-05 5.8319e-02 1.9848e-05 2.5511e-04\n",
      "   7.6890e-06 2.3961e-04 7.4463e-01]\n",
      "  [9.1195e-06 1.6727e-03 5.8532e-05 2.4967e-03 8.1956e-05 9.4543e-02\n",
      "   4.8161e-05 2.6016e-03 4.8876e-05 1.9150e-02 1.2338e-05 1.4400e-04\n",
      "   5.0664e-06 1.2493e-04 8.7891e-01]\n",
      "  [1.2338e-05 3.3736e-04 5.6744e-05 3.7146e-04 9.7275e-05 2.0294e-02\n",
      "   5.0545e-05 3.0327e-04 6.1750e-05 2.4223e-03 1.2994e-05 2.7895e-05\n",
      "   3.6955e-06 3.9935e-05 9.7607e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]\n",
      "  [3.9429e-02 1.1847e-01 2.8488e-02 6.6406e-02 7.4280e-02 1.7065e-01\n",
      "   2.7145e-02 8.9539e-02 2.4567e-02 7.9834e-02 1.7807e-02 3.7506e-02\n",
      "   3.9551e-02 7.3059e-02 1.1328e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it, stage=test]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\n",
    "df_ids = df[\"id\"].unique()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args1.model)\n",
    "test_samples = prepare_test_data(df, tokenizer, args1)\n",
    "collate = Collate(tokenizer=tokenizer)\n",
    "\n",
    "raw_preds = []\n",
    "for fold_ in range(1):\n",
    "    current_idx = 0\n",
    "    test_dataset = FeedbackDataset(test_samples, args1.max_len, tokenizer)\n",
    "    \n",
    "    if fold_ < 5:\n",
    "        model = FeedbackModel(model_name=args1.model, num_labels=len(target_id_map) - 1)\n",
    "        model.load(os.path.join(args1.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n",
    "        preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "    else:\n",
    "        model = FeedbackModel(model_name=args2.model, num_labels=len(target_id_map) - 1)\n",
    "        model.load(os.path.join(args2.tez_model, f\"model_{fold_-5}.bin\"), weights_only=True)\n",
    "        preds_iter = model.predict(test_dataset, batch_size=args2.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "        \n",
    "    current_idx = 0\n",
    "    \n",
    "    print(\"preds_iter\")\n",
    "    print(preds_iter)\n",
    "    \n",
    "    \n",
    "    for preds in preds_iter:\n",
    "        preds = preds.astype(np.float16)\n",
    "        print(\"preds\",preds)\n",
    "        preds = preds / 10\n",
    "        if fold_ == 0:\n",
    "            raw_preds.append(preds)\n",
    "        else:\n",
    "            raw_preds[current_idx] += preds\n",
    "            current_idx += 1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_preds[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.95e-06\n"
     ]
    }
   ],
   "source": [
    "print(raw_preds[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10004669427871704\n"
     ]
    }
   ],
   "source": [
    "print(sum(raw_preds[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '18409261F5C2', 'input_ids': [100, 109, 45, 101, 4758, 4], 'text': 'I do not like cat.', 'offset_mapping': [(0, 1), (2, 4), (5, 8), (9, 13), (14, 17), (17, 18)], 'preds': ['O', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'O', 'O'], 'pred_scores': [0.05682373046875, 0.05426025390625, 0.05535888671875, 0.053955078125, 0.044189453125, 0.06439208984375, 0.0982666015625]}, {'id': 'D46BCB48440A', 'input_ids': [100, 4758, 4], 'text': 'I cat.', 'offset_mapping': [(0, 1), (2, 5), (5, 6)], 'preds': ['O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.09173583984375, 0.093505859375, 0.09521484375, 0.0970458984375, 0.017059326171875, 0.017059326171875, 0.017059326171875]}, {'id': '0FB0700DAF44', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)], 'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.078369140625, 0.06536865234375, 0.074462890625, 0.087890625, 0.09759521484375, 0.017059326171875, 0.017059326171875]}, {'id': 'D72CB1C11673', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)], 'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.078369140625, 0.06536865234375, 0.074462890625, 0.087890625, 0.09759521484375, 0.017059326171875, 0.017059326171875]}, {'id': 'DF920E0A7337', 'input_ids': [100, 101, 4758, 4], 'text': 'I like cat.', 'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)], 'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'], 'pred_scores': [0.078369140625, 0.06536865234375, 0.074462890625, 0.087890625, 0.09759521484375, 0.017059326171875, 0.017059326171875]}]\n"
     ]
    }
   ],
   "source": [
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '18409261F5C2',\n",
      "  'input_ids': [100, 109, 45, 101, 4758, 4],\n",
      "  'offset_mapping': [(0, 1), (2, 4), (5, 8), (9, 13), (14, 17), (17, 18)],\n",
      "  'pred_scores': [0.05682373046875,\n",
      "                  0.05426025390625,\n",
      "                  0.05535888671875,\n",
      "                  0.053955078125,\n",
      "                  0.044189453125,\n",
      "                  0.06439208984375,\n",
      "                  0.0982666015625],\n",
      "  'preds': ['O',\n",
      "            'I-Concluding Statement',\n",
      "            'I-Concluding Statement',\n",
      "            'I-Concluding Statement',\n",
      "            'O',\n",
      "            'O',\n",
      "            'O'],\n",
      "  'text': 'I do not like cat.'},\n",
      " {'id': 'D46BCB48440A',\n",
      "  'input_ids': [100, 4758, 4],\n",
      "  'offset_mapping': [(0, 1), (2, 5), (5, 6)],\n",
      "  'pred_scores': [0.09173583984375,\n",
      "                  0.093505859375,\n",
      "                  0.09521484375,\n",
      "                  0.0970458984375,\n",
      "                  0.017059326171875,\n",
      "                  0.017059326171875,\n",
      "                  0.017059326171875],\n",
      "  'preds': ['O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence', 'I-Evidence'],\n",
      "  'text': 'I cat.'},\n",
      " {'id': '0FB0700DAF44',\n",
      "  'input_ids': [100, 101, 4758, 4],\n",
      "  'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)],\n",
      "  'pred_scores': [0.078369140625,\n",
      "                  0.06536865234375,\n",
      "                  0.074462890625,\n",
      "                  0.087890625,\n",
      "                  0.09759521484375,\n",
      "                  0.017059326171875,\n",
      "                  0.017059326171875],\n",
      "  'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'],\n",
      "  'text': 'I like cat.'},\n",
      " {'id': 'D72CB1C11673',\n",
      "  'input_ids': [100, 101, 4758, 4],\n",
      "  'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)],\n",
      "  'pred_scores': [0.078369140625,\n",
      "                  0.06536865234375,\n",
      "                  0.074462890625,\n",
      "                  0.087890625,\n",
      "                  0.09759521484375,\n",
      "                  0.017059326171875,\n",
      "                  0.017059326171875],\n",
      "  'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'],\n",
      "  'text': 'I like cat.'},\n",
      " {'id': 'DF920E0A7337',\n",
      "  'input_ids': [100, 101, 4758, 4],\n",
      "  'offset_mapping': [(0, 1), (2, 6), (7, 10), (10, 11)],\n",
      "  'pred_scores': [0.078369140625,\n",
      "                  0.06536865234375,\n",
      "                  0.074462890625,\n",
      "                  0.087890625,\n",
      "                  0.09759521484375,\n",
      "                  0.017059326171875,\n",
      "                  0.017059326171875],\n",
      "  'preds': ['O', 'O', 'O', 'O', 'O', 'I-Evidence', 'I-Evidence'],\n",
      "  'text': 'I like cat.'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in raw_preds:\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n",
    "\n",
    "for j in range(len(test_samples)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    test_samples[j][\"preds\"] = tt\n",
    "    test_samples[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "\n",
    "\n",
    "def link_evidence(oof):\n",
    "    thresh = 1\n",
    "    idu = oof['id'].unique()\n",
    "    idc = idu[1]\n",
    "    eoof = oof[oof['class'] == \"Evidence\"]\n",
    "    neoof = oof[oof['class'] != \"Evidence\"]\n",
    "    for thresh2 in range(26,27, 1):\n",
    "        retval = []\n",
    "        for idv in idu:\n",
    "            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
    "                   'Counterclaim', 'Rebuttal']:\n",
    "                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n",
    "                if len(q) == 0:\n",
    "                    continue\n",
    "                pst = []\n",
    "                for i,r in q.iterrows():\n",
    "                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n",
    "                start = 1\n",
    "                end = 1\n",
    "                for i in range(2,len(pst)):\n",
    "                    cur = pst[i]\n",
    "                    end = i\n",
    "                    #if pst[start] == 205:\n",
    "                    #   print(cur, pst[start], cur - pst[start])\n",
    "                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n",
    "                        retval.append((idv, c, jn(pst, start, end)))\n",
    "                        start = i + 1\n",
    "                v = (idv, c, jn(pst, start, end+1))\n",
    "                #print(v)\n",
    "                retval.append(v)\n",
    "        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n",
    "        roof = roof.merge(neoof, how='outer')\n",
    "        return roof\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23109/334682447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23109/185455024.py\u001b[0m in \u001b[0;36mlink_evidence\u001b[0;34m(oof)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0midu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0midc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0meoof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mneoof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "proba_thresh = {\n",
    "    \"Lead\": 0.7,\n",
    "    \"Position\": 0.55,\n",
    "    \"Evidence\": 0.65,\n",
    "    \"Claim\": 0.55,\n",
    "    \"Concluding Statement\": 0.7,\n",
    "    \"Counterclaim\": 0.5,\n",
    "    \"Rebuttal\": 0.55,\n",
    "}\n",
    "\n",
    "min_thresh = {\n",
    "    \"Lead\": 9,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 14,\n",
    "    \"Claim\": 3,\n",
    "    \"Concluding Statement\": 11,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 4,\n",
    "}\n",
    "\n",
    "submission = []\n",
    "for sample_idx, sample in enumerate(test_samples):\n",
    "    preds = sample[\"preds\"]\n",
    "    offset_mapping = sample[\"offset_mapping\"]\n",
    "    sample_id = sample[\"id\"]\n",
    "    sample_text = sample[\"text\"]\n",
    "    sample_input_ids = sample[\"input_ids\"]\n",
    "    sample_pred_scores = sample[\"pred_scores\"]\n",
    "    sample_preds = []\n",
    "\n",
    "    if len(preds) < len(offset_mapping):\n",
    "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "    \n",
    "    idx = 0\n",
    "    phrase_preds = []\n",
    "    while idx < len(offset_mapping):\n",
    "        start, _ = offset_mapping[idx]\n",
    "        if preds[idx] != \"O\":\n",
    "            label = preds[idx][2:]\n",
    "        else:\n",
    "            label = \"O\"\n",
    "        phrase_scores = []\n",
    "        phrase_scores.append(sample_pred_scores[idx])\n",
    "        idx += 1\n",
    "        while idx < len(offset_mapping):\n",
    "            if label == \"O\":\n",
    "                matching_label = \"O\"\n",
    "            else:\n",
    "                matching_label = f\"I-{label}\"\n",
    "            if preds[idx] == matching_label:\n",
    "                _, end = offset_mapping[idx]\n",
    "                phrase_scores.append(sample_pred_scores[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if \"end\" in locals():\n",
    "            phrase = sample_text[start:end]\n",
    "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "\n",
    "    temp_df = []\n",
    "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "        word_start = len(sample_text[:start].split())\n",
    "        word_end = word_start + len(sample_text[start:end].split())\n",
    "        word_end = min(word_end, len(sample_text.split()))\n",
    "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "        if label != \"O\":\n",
    "            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                if len(ps.split()) >= min_thresh[label]:\n",
    "                    temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "    submission.append(temp_df)\n",
    "\n",
    "submission = pd.concat(submission).reset_index(drop=True)\n",
    "submission = link_evidence(submission)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
